{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cd83c8-9a7d-4968-b8e7-768685c3f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import urllib.request\n",
    "from moviepy.editor import *\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4369016b-7842-4bba-a143-06dfaa4d1ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Azure\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "#init Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "OPENAI_LANGUAGE_KEY = os.getenv(\"OPENAI_LANGUAGE_KEY\")\n",
    "OPENAI_LANGUAGE_ENDPOINT = os.getenv(\"OPENAI_LANGUAGE_ENDPOINT\")\n",
    "OPENAI_SPEECH_KEY = os.getenv(\"OPENAI_SPEECH_KEY\")\n",
    "OPENAI_SPEECH_REGION = os.getenv(\"OPENAI_SPEECH_REGION\")\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73d3940-2481-4a91-895a-a105edda7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the content:  HTML Hello World Tutorial: Generate a beginner-friendly tutorial for creating a basic \"Hello World\" webpage using HTML.\n"
     ]
    }
   ],
   "source": [
    "num_of_sentences = 1\n",
    "content = input(\"Please enter the content: \")\n",
    "prompt = 'Provide a summary of the text below that captures its main idea in '+ str(num_of_sentences) +'sentences. \\n' + content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9caded39-68e2-4691-8224-894333698bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_summ = openai.Completion.create(\n",
    "  engine=OPENAI_DEPLOYMENT_NAME,\n",
    "  prompt=prompt,\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3139e3ec-cec9-463b-b0b7-144566e54fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Provide a summary of the text below that captures its main idea in 1sentences. \n",
      "CSS Box Model Tutorial: Generate a beginner-friendly tutorial for understanding the CSS box model and how it affects the layout of a webpage. \n",
      "\n",
      "Provide a summary of the text below that captures its main idea in 1sentences. \n",
      "JavaScript Variables Tutorial: Generate a beginner-friendly tutorial for understanding JavaScript variables and how they are used to store data. \n",
      "\n",
      "Provide a summary of the text below that captures its main\n"
     ]
    }
   ],
   "source": [
    "print(response_summ.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89845e20-d41f-4060-ac11-5e24536a76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(OPENAI_LANGUAGE_KEY)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=OPENAI_LANGUAGE_ENDPOINT,\n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39a054c-42d4-4751-8614-620cef140a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "    try:\n",
    "        phrase_list, phrases = [], ''\n",
    "        documents = [response_summ.choices[0].text]\n",
    "        response_kp = client.extract_key_phrases(documents = documents)[0]\n",
    "        if not response_kp.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response_kp.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "                phrase_list.append(phrase)\n",
    "                phrases = phrases +\"\\n\"+ phrase          \n",
    "        else:\n",
    "            print(response_kp.id, response_kp.error)\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "    return phrase_list, phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5509c3-a2d9-4871-a011-212536d03abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKey Phrases:\n",
      "\t\t CSS Box Model Tutorial\n",
      "\t\t beginner-friendly tutorial\n",
      "\t\t JavaScript Variables\n",
      "\t\t main idea\n",
      "\t\t summary\n",
      "\t\t text\n",
      "\t\t 1sentences\n",
      "\t\t layout\n",
      "\t\t webpage\n",
      "\t\t data\n"
     ]
    }
   ],
   "source": [
    "phrase_list, phrases = key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d98ccd-55fb-4a92-9d78-637886b0da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' Provide an image idea for each phrases: ''' + phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20cfd2c7-0ccf-46dc-88cc-37bf1a2f10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['functions', 'loops', 'arrays', 'objects', 'DOM manipulation', 'events', 'jQuery', 'Bootstrap', 'media queries', 'responsive design', 'flexbox', 'grid', 'animation', 'transitions', 'transformations', 'SVG', 'canvas', 'web animation API', 'webGL', 'three.js', 'React', 'Redux', 'Angular', 'Vue.js', 'Node.js', 'Express.js', 'MongoDB', 'Firebase', 'API', 'RESTful', 'GraphQL', 'Webpack', 'Babel', 'TypeScript', 'ES6', 'ES7', 'ES8', 'ES9', 'ES']\n"
     ]
    }
   ],
   "source": [
    "response_phrase  = openai.Completion.create(\n",
    "  engine=OPENAI_DEPLOYMENT_NAME,\n",
    "  prompt=prompt,\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    ")\n",
    "\n",
    "image_phrases = response_phrase.choices[0].text.split(\"\\n\")[1:]\n",
    "print(image_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be70c43-d1ab-403c-ac45-a2db299c45af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animation', 'functions', 'flexbox', 'arrays', 'TypeScript', 'Express.js', 'events', 'responsive design', 'Redux', 'API', 'RESTful', 'React', 'DOM manipulation', 'Node.js', 'jQuery', 'ES6', 'webGL', 'Webpack', 'three.js', 'ES7', 'objects', 'ES9', 'Firebase', 'web animation API', 'MongoDB', 'grid', 'SVG', 'transitions', 'ES8', 'loops', 'Babel', 'Vue.js', 'Angular', 'canvas', 'ES', 'media queries', 'transformations', 'Bootstrap', 'GraphQL']\n"
     ]
    }
   ],
   "source": [
    "im_ph = []\n",
    "\n",
    "for image_phrase in image_phrases:\n",
    "\n",
    "\n",
    "    if(len(image_phrase) > 0):\n",
    "        \n",
    "        im_ph.append(image_phrase.split(\":\")[0])\n",
    "\n",
    "# Convert the list to a set to remove duplicates, then back to a list\n",
    "im_ph = list(set(im_ph))\n",
    "\n",
    "print(im_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a53b7a9-af26-49f1-b043-549d5b32a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for phrase in im_ph:\n",
    "    response = openai.Image.create(\n",
    "        prompt=phrase,\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    image_url = response[\"data\"][0][\"url\"]\n",
    "    images.append(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c619d7-1eba-433b-a0bb-7b0434b34db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading done.....\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for url in images:\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    filename = \"file\" + str(counter) + \".jpg\"\n",
    "\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "    image_list.append(filename)\n",
    "\n",
    "print (\"Downloading done.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367833f2-4c3d-401a-bb72-b13db08bdee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.cognitiveservices.speech.SpeechConfig object at 0x0000022DEC41FA10>\n"
     ]
    }
   ],
   "source": [
    "speech_config = speechsdk.SpeechConfig(subscription=OPENAI_SPEECH_KEY, region=OPENAI_SPEECH_REGION)\n",
    "print(speech_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2556c83-ccd1-410d-b9bb-ebc6abc1c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, filename):\n",
    "    audio_config = speechsdk.AudioConfig(filename=filename)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    result = speech_synthesizer.speak_text_async(text).get()\n",
    "    print(result)\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Audio saved to {filename}\")\n",
    "    else:\n",
    "        print(f\"Error: {result.error_details}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bdde8ab-7530-4eee-ae67-dea74df8ef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechSynthesisResult(result_id=0b73824e1fce4d6681b65de66d4cb691, reason=ResultReason.SynthesizingAudioCompleted, audio_length=1018846)\n",
      "Audio saved to audio.mp4\n"
     ]
    }
   ],
   "source": [
    "text = response_summ.choices[0].text\n",
    "filename = \"audio.mp4\"\n",
    "text_to_speech(text, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e27b002-8f7a-479a-81be-1c9082036705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the video.....\n",
      "Moviepy - Building video video.mp4.\n",
      "MoviePy - Writing audio in videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready video.mp4\n",
      "Video created.....\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the video.....\")\n",
    "def create_video(images, audio, output):\n",
    "    resized_images = [np.array(Image.open(img).resize((1024, 1024))) for img in images]\n",
    "    clips = [ImageClip(img).set_duration(2) for img in resized_images]\n",
    "    concat_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "    audio_clip = AudioFileClip(audio)\n",
    "    final_clip = concat_clip.set_audio(audio_clip)\n",
    "    final_clip.write_videofile(output, fps=24)\n",
    "images = image_list\n",
    "audio = filename\n",
    "output = \"video.mp4\"\n",
    "create_video(images, audio, output)\n",
    "print(\"Video created.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188ebef-8bd5-4c8b-a411-786675c311d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
